{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and set up default plot params\n",
    "\n",
    "#### Note, this cell picks the path from which you want to load tha data and to which you want to save all figures as your current working directory (`cwd`).\n",
    "#### If you want to load from/save to a different path, edit the `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.stats import binned_statistic_2d\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, PowerTransformer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import brier_score_loss, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set default tick label size\n",
    "matplotlib.rcParams.update({'xtick.labelsize': 16})\n",
    "matplotlib.rcParams.update({'ytick.labelsize': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv file\n",
    "df = pd.read_csv(path + '/' + 'haberman.data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide the columns into inputs (age, year, nodes) and outputs (state), and encode the output/target variable (y) to have values 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "\n",
    "# split into input and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# label encode the target variable to have the classes 0 and 1\n",
    "y = LabelEncoder().fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for evaluating the skill of the model\n",
    "\n",
    "#### Use the Brier score, which calculates the mean squared error between the model predicted probabilities and the probabilities expected from the reference dataset\n",
    "We calculate the reference dataset Brier score, where per_pos represents the expected baseline performance for the predictive model, and the model Brier score\n",
    "\n",
    "We then calculate the model skill score, by comparing the Brier score for the reference and the model\n",
    "By default, a skill score of 0.0 is a perfect score, but we invert such that 1.0 is a perfect score, and a score of 0.0 means the model performs exactly as well as the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Brier skill score (BSS)\n",
    "# Use as a metric for evaluating the skill of the model based on the returned predicted probabilities\n",
    "def brier_skill_score(y_true, y_prob):\n",
    "    # Calculate Brier score for the reference (i.e., the dataset)\n",
    "    ref_probs = [per_pos for _ in range(len(y_true))]\n",
    "    bs_ref = brier_score_loss(y_true, ref_probs)\n",
    "    # Calculate Brier score for the predictive model\n",
    "    bs_model = brier_score_loss(y_true, y_prob)\n",
    "    # Calculate skill score, by comparing the Brier score for the reference and the model\n",
    "    print(1.0 - (bs_model / bs_ref))\n",
    "    return 1.0 - (bs_model / bs_ref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use cross-validation, which uses a limited sample of a dataset in order to estimate the skill of a model, or how the model is expected to perform when used to make predictions on data not used in the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(X, y, model):\n",
    "    # k-fold cross-validation\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # Tell the scorer what metric to use\n",
    "    metric = make_scorer(brier_skill_score, needs_proba=True)\n",
    "    # Evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline and fit the model\n",
    "model = Pipeline(steps=[('t1', MinMaxScaler()), ('t2', PowerTransformer()),('m',LogisticRegression(solver='lbfgs'))])\n",
    "model.fit(X, y)\n",
    "\n",
    "print('Model fit complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the model to a new patient\n",
    "\n",
    "### Requires user to input patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = float(input('What was the age of the patient at the time of the operation?: '))\n",
    "year = float(input('In what year was the surgery performed?: ')) - 1900.0\n",
    "nodes = float(input('How many positive axillary nodes were detected in the patient?: '))\n",
    "# some new cases\n",
    "data = [[age,year,nodes]]\n",
    "for row in data:\n",
    "    # Make model prediction\n",
    "    yhat = model.predict_proba([row])\n",
    "    # Probability of survival\n",
    "    p_survive = yhat[0, 0] * 100\n",
    "    # Summarize\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('A {0:.0f}-year-old patient undergoing the breast cancer surgery in {1:.0f}'.format(age, year + 1900.0))\n",
    "    print('with {0:.0f} positive axillary nodes detected has a {1:.2f}% chance of long-term survival.'.format(nodes, p_survive))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more test cases\n",
    "\n",
    "#### Here, we'll check a few patients, pulled directly from the dataset, that we know survived (state 1) or did not survive (state 2) for longer than 5 years after their surgery. The model will output the probability of survival for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Cases:')\n",
    "data = [[66,58,0], [52,69,3], [36,60,1], [38,60,0], [53,59,3]] #1,2,1,1,2 \n",
    "for row in data:\n",
    "    # Make model prediction\n",
    "    yhat = model.predict_proba([row])\n",
    "    # Probability of survival\n",
    "    p_survive = yhat[0, 0] * 100\n",
    "    # Summarize\n",
    "    print('data=%s, Survival=%.3f%%' % (row, p_survive))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make some plots showing the entire parameters space on which the model was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the entire parameter space\n",
    "ages = np.arange(np.min(df['AGE']), np.max(df['AGE'])+1, 1)\n",
    "years = np.arange(np.min(df['YEAR']), np.max(df['YEAR'])+1, 1)\n",
    "nodes = np.arange(np.min(df['NODES']), np.max(df['NODES'])+1, 1)\n",
    "\n",
    "prob = []\n",
    "for i,a in enumerate(ages):\n",
    "    for j,y in enumerate(years):\n",
    "        for k,n in enumerate(nodes):\n",
    "            # Get patient data\n",
    "            row = [a,y,k]\n",
    "            # Make model prediction\n",
    "            yhat = model.predict_proba([row])\n",
    "            # Probability of survival, as a fraction from 0.0 to 1.0, and save results\n",
    "            p_survive = yhat[0, 0]\n",
    "            prob.append([a,y,k,p_survive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2,2, figsize=(18,16))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1,hspace=0.1)\n",
    "\n",
    "ages_model = []\n",
    "year_model = []\n",
    "node_model = []\n",
    "prob_model = []\n",
    "for i,p in enumerate(prob):\n",
    "    ages_model.append(p[0])\n",
    "    year_model.append(p[1])\n",
    "    node_model.append(p[2])\n",
    "    prob_model.append(p[3])\n",
    "\n",
    "ret_ay = binned_statistic_2d(ages_model, year_model, prob_model, statistic=np.median, bins=[ages, years])\n",
    "im = axarr[0,0].imshow(ret_ay.statistic.T, origin='bottom', \n",
    "                       cmap='RdYlGn', aspect='auto', extent=(np.min(ages), np.max(ages), np.min(years), np.max(years)),\n",
    "                       vmin=0.25, vmax=1.0, norm=matplotlib.colors.LogNorm())\n",
    "axarr[0,0].text(33,68,'$[1]$',fontsize=20)\n",
    "\n",
    "ret_an = binned_statistic_2d(ages_model, node_model, prob_model, statistic=np.median, bins=[ages, nodes])\n",
    "axarr[1,0].imshow(ret_an.statistic.T, origin='bottom', \n",
    "                       cmap='RdYlGn', aspect='auto', extent=(np.min(ages), np.max(ages), np.min(nodes), np.max(nodes)),\n",
    "                       vmin=0.25, vmax=1.0, norm=matplotlib.colors.LogNorm())\n",
    "axarr[1,0].text(33,47,'$[2]$',fontsize=20)\n",
    "    \n",
    "ret_yn = binned_statistic_2d(year_model, node_model, prob_model, statistic=np.median, bins=[years, nodes])\n",
    "axarr[1,1].imshow(ret_yn.statistic.T, origin='bottom', \n",
    "                       cmap='RdYlGn', aspect='auto', extent=(np.min(years), np.max(years), np.min(nodes), np.max(nodes)),\n",
    "                       vmin=0.25, vmax=1.0, norm=matplotlib.colors.LogNorm())\n",
    "axarr[1,1].text(59,47,'$[3]$',fontsize=20)\n",
    "\n",
    "axarr[0,1].axis('off')\n",
    "\n",
    "axarr[0,0].set_ylabel('Year of surgery',fontsize=20)\n",
    "axarr[1,0].set_xlabel('Age of patient at time of surgery',fontsize=20)\n",
    "axarr[1,0].set_ylabel('Number of positive axillary nodes detected',fontsize=20)\n",
    "axarr[1,1].set_xlabel('Year of surgery',fontsize=20)\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axarr.ravel().tolist(), ticks=[0.3, 0.4, 0.6, 1.0], pad=0.025)\n",
    "cbar.set_label(label='Probability of long-term survival', fontsize=20)\n",
    "cbar.ax.set_yticklabels(['30%', '40%', '60%', '100%'])\n",
    "\n",
    "plt.savefig(path + '/' + 'haberman_corner_survival.pdf', fig=fig, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
